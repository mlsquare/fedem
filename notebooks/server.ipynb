{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mlsquare/mergekit-mamba.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, ModelFilter\n",
    "from peft import PeftMixedModel\n",
    "\n",
    "\n",
    "def get_models_by_organization(org_id):\n",
    "    api = HfApi()\n",
    "    new_filter = ModelFilter(tags=\"mamba\")\n",
    "    models = api.list_models(filter=new_filter)\n",
    "    models_list = []\n",
    "    for i in models:\n",
    "        print(i.modelId)\n",
    "        if org_id in i.modelId:\n",
    "            models_list.append(i.modelId)\n",
    "    return models_list\n",
    "\n",
    "\n",
    "org_id = \"mlsquare\"\n",
    "models = get_models_by_organization(org_id)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"small\": [\n",
    "        \"mlsquare/mamba_130M_small_out_proj\",\n",
    "        \"mlsquare/mamba_130M_small_d_proj\",\n",
    "        \"mlsquare/mamba_130M_small_x_proj\",\n",
    "    ],\n",
    "    \"large\": [\"mlsquare/mamba_130M_large_x_d_out_proj\"],\n",
    "}\n",
    "\n",
    "\n",
    "def compute_loss(model, inputs, return_outputs=False):\n",
    "    input_ids = inputs.pop(\"input_ids\")\n",
    "    lm_logits = model(input_ids)[0]\n",
    "    labels = input_ids.to(lm_logits.device)\n",
    "\n",
    "    shift_logits = lm_logits[:, :-1, :].contiguous()\n",
    "    labels = labels[:, 1:].contiguous()\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    lm_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), labels.view(-1))\n",
    "    return lm_loss\n",
    "\n",
    "\n",
    "def evaluation(data_path, model):\n",
    "    data = load_dataset(data_path).shuffle()\n",
    "    tokenized_data = data.map(tokenize, batched=True, remove_columns=data.column_names)\n",
    "    val = 0\n",
    "    for i in data[\"tgt\"]:\n",
    "        val += compute_loss(model, i)\n",
    "    print(val / len(data[\"tgt\"]))\n",
    "    return val / len(data[\"tgt\"])\n",
    "\n",
    "\n",
    "def model_merge_large(adapters, model_path, data_path):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    model.load_adapter(adapters[\"large\"][0])\n",
    "    result = evaluation(data_path, model)\n",
    "\n",
    "\n",
    "def model_merge_small(adapters, model_path, data_path):\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "    peft_model = PeftMixedModel.from_pretrained(base_model, adapters[\"small\"][0])\n",
    "    peft_model.load_adapter(adapters[\"small\"][1], adapter_name=\"1\")\n",
    "    peft_model.load_adapter(adapters[\"small\"][2], adapter_name=\"2\")\n",
    "    peft_model.set_adapter([\"default\", \"1\", \"2\", \"3\"])\n",
    "    result = evaluation(data_path, model)\n",
    "\n",
    "\n",
    "def create_JSON(value):\n",
    "    json_data = json.dumps(value, indent=4)\n",
    "    with open(f\"{value}\", \"w\") as json_file:\n",
    "        json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "<model>-<PARAMS>-<AdapterComputation>-<target_modules>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_130M_small_out_proj = {\n",
    "    \"model_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"tokenizer_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"target_modules\": [\"out_proj\"],\n",
    "    \"adapter_path\": \"mlsquare/mamba-130M-small-out_proj\",\n",
    "    \"data\": \"mlsquare/samantar1per_cent_merged_with_train_val\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_130M_small_d_proj = {\n",
    "    \"model_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"tokenizer_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"target_modules\": [\"d_proj\"],\n",
    "    \"adapter_path\": \"mlsquare/mamba-130M-small-out_proj\",\n",
    "    \"data\": \"mlsquare/samantar1per_cent_merged_with_train_val\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_130M_small_x_proj = {\n",
    "    \"model_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"tokenizer_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"target_modules\": [\"x_proj\"],\n",
    "    \"adapter_path\": \"mlsquare/mamba-130M-small-out_proj\",\n",
    "    \"data\": \"mlsquare/samantar1per_cent_merged_with_train_val\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_130M_large_x_d_out_proj = {\n",
    "    \"model_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"tokenizer_path\": \"Q-bert/Mamba-130M\",\n",
    "    \"target_modules\": [\"x_proj\", \"d_proj\", \"out_proj\"],\n",
    "    \"adapter_path\": \"mlsquare/mamba-130M-small-out_proj\",\n",
    "    \"data\": \"mlsquare/samantar1per_cent_merged_with_train_val\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
