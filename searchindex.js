Search.setIndex({"docnames": ["fedem", "fedem.client", "fedem.configurations", "fedem.models", "fedem.server", "fedem.trainer", "fedem.utils", "index", "modules"], "filenames": ["fedem.rst", "fedem.client.rst", "fedem.configurations.rst", "fedem.models.rst", "fedem.server.rst", "fedem.trainer.rst", "fedem.utils.rst", "index.rst", "modules.rst"], "titles": ["fedem package", "fedem.client package", "fedem.configurations package", "fedem.models package", "fedem.server package", "fedem.trainer package", "fedem.utils package", "Welcome to fedem\u2019s documentation!", "fedem"], "terms": {"client": [0, 6, 7, 8], "seshu": [0, 1, 4, 8], "push_to_hub": [0, 1, 8], "token": [0, 1, 4, 5, 6, 8], "train_lora": [0, 1, 8], "configur": [0, 3, 4, 6, 7, 8], "submodul": [0, 7, 8], "mamba": [0, 5, 7, 8], "mambaconfig": [0, 2, 3, 4, 8], "model_typ": [0, 2, 8], "model": [0, 1, 4, 5, 6, 7, 8], "mambablock": [0, 3, 8], "forward": [0, 3, 8], "selective_scan": [0, 3, 8], "ssm": [0, 3, 8], "mambaforcausallm": [0, 3, 6, 8], "get_decod": [0, 3, 8], "get_input_embed": [0, 3, 8], "get_output_embed": [0, 3, 8], "prepare_inputs_for_gener": [0, 3, 8], "set_decod": [0, 3, 8], "set_input_embed": [0, 3, 8], "set_output_embed": [0, 3, 8], "mambamodel": [0, 3, 8], "mambapretrainedmodel": [0, 3, 8], "base_model_prefix": [0, 3, 8], "config_class": [0, 3, 8], "supports_gradient_checkpoint": [0, 3, 8], "mambarmsnorm": [0, 3, 8], "server": [0, 7, 8], "mambatrain": [0, 4, 5, 8], "compute_loss": [0, 4, 5, 8], "model_merge_ev": [0, 4, 8], "pretrain": [0, 4, 8], "create_json": [0, 4, 8], "evalu": [0, 4, 8], "get_checkpoint_model": [0, 4, 6, 8], "get_data": [0, 4, 8], "load_data": [0, 4, 6, 8], "load_json": [0, 4, 6, 8], "make_config": [0, 4, 6, 8], "model_merg": [0, 4, 8], "print_trainable_paramet": [0, 4, 6, 8], "trainer": [0, 4, 7, 8], "util": [0, 7, 8], "huggingfac": [0, 7, 8], "get_client_detail": [0, 6, 8], "verify_user_with_org": [0, 6, 8], "load_model": [0, 6, 8], "load_model_pretrain": [0, 6, 8], "load_model_with_lora": [0, 6, 8], "load_token": [0, 6, 8], "split_data": [0, 6, 8], "class": [1, 2, 3, 4, 5], "hf_model_path": 1, "str": [1, 2, 4, 5, 6], "hf_tokenizer_path": 1, "target_modul": [1, 6], "list": [1, 4, 5, 6], "hf_adapter_path": 1, "hf_data_path": 1, "org_id": [1, 4, 6], "mlsquar": [1, 4], "hf_token": [1, 4, 6], "none": [1, 3, 4, 5, 6], "sourc": [1, 2, 3, 4, 5, 6], "base": [1, 2, 3, 4, 5, 6], "object": [1, 4], "push": 1, "file": [1, 6], "hug": [1, 6], "face": [1, 6], "hub": 1, "data_to_token": 1, "input": [1, 3, 4, 5], "data": [1, 4, 6], "paramet": [1, 3, 4, 5, 6], "return": [1, 3, 4, 5, 6], "type": [1, 3, 4, 5, 6], "dict": [1, 4, 5, 6], "training_arg": 1, "trainingargu": [1, 4, 5], "debug": [1, 4], "bool": [1, 3, 4, 5, 6], "fals": [1, 2, 4, 5, 6], "train": [1, 3, 4, 5, 6], "us": [1, 3], "lora": [1, 6], "option": [1, 3, 4, 5, 6], "argument": 1, "default": [1, 3, 4, 5, 6], "mode": 1, "flag": 1, "vocab_s": 2, "50277": 2, "d_state": 2, "16": 2, "d_model": [2, 3], "2560": 2, "d_conv": 2, "4": [2, 3], "expand": 2, "2": [2, 3], "conv_bia": 2, "true": [2, 3], "bia": 2, "n_layer": 2, "64": 2, "dt_rank": 2, "int": [2, 3, 4], "auto": 2, "pad_vocab_size_multipl": 2, "8": 2, "initializer_rang": 2, "0": [2, 4], "02": 2, "kwarg": [2, 3], "pretrainedconfig": [2, 3], "config": [3, 6], "block": 3, "describ": 3, "paper": 3, "x": 3, "thi": 3, "look": 3, "same": 3, "figur": 3, "3": 3, "section": 3, "1": 3, "shape": 3, "b": 3, "l": 3, "d": 3, "see": 3, "glossari": 3, "top": 3, "definit": 3, "d_in": 3, "n": 3, "output": [3, 5], "offici": 3, "implement": 3, "http": 3, "github": 3, "com": 3, "state": 3, "space": 3, "blob": 3, "main": 3, "mamba_ssm": 3, "mamba_simpl": 3, "py": 3, "l119": 3, "mamba_inner_ref": 3, "op": 3, "selective_scan_interfac": 3, "l311": 3, "u": 3, "delta": 3, "A": 3, "c": 3, "doe": 3, "select": 3, "scan": 3, "algorithm": 3, "run_ssm": 3, "The": [3, 4, 6], "annot": 3, "s4": 3, "i": [3, 6], "classic": 3, "discret": 3, "formula": 3, "t": 3, "ax": 3, "bu": 3, "y": 3, "cx": 3, "du": 3, "except": 3, "step": 3, "size": 3, "which": 3, "ar": 3, "depend": 3, "selective_scan_ref": 3, "l86": 3, "note": 3, "refactor": 3, "some": 3, "part": [3, 6], "out": 3, "so": 3, "function": 3, "doesn": 3, "match": 3, "exactli": 3, "run": 3, "causal": 3, "languag": [3, 4, 5], "input_id": 3, "longtensor": 3, "label": 3, "output_attent": 3, "output_hidden_st": 3, "return_dict": 3, "tupl": [3, 4, 5, 6], "causallmoutputwithpast": 3, "defin": 3, "comput": [3, 4, 5], "perform": 3, "everi": 3, "call": 3, "should": 3, "overridden": 3, "all": 3, "subclass": [3, 5], "although": 3, "recip": 3, "pass": 3, "need": 3, "within": 3, "one": 3, "instanc": 3, "afterward": 3, "instead": 3, "sinc": 3, "former": 3, "take": 3, "care": 3, "regist": 3, "hook": 3, "while": 3, "latter": 3, "silent": 3, "ignor": 3, "them": 3, "": 3, "embed": 3, "torch": [3, 4, 5], "map": 3, "vocabulari": 3, "hidden": 3, "nn": 3, "decod": 3, "valu": [3, 4], "set": [3, 6], "new_embed": 3, "architectur": 3, "consist": 3, "basemodeloutputwithpast": 3, "pretrainedmodel": [3, 4, 5], "pre": [3, 6], "alia": 3, "ep": 3, "float": [3, 4], "1e": 3, "05": 3, "root": 3, "mean": 3, "squar": 3, "normal": 3, "dimens": 3, "epsilon": 3, "numer": 3, "stabil": 3, "5": 3, "arg": [4, 5], "data_col": [4, 5], "datacol": [4, 5], "train_dataset": [4, 5], "dataset": [4, 5, 6], "eval_dataset": [4, 5], "pretrainedtokenizerbas": [4, 5], "model_init": [4, 5], "callabl": [4, 5], "compute_metr": [4, 5], "evalpredict": [4, 5], "callback": [4, 5], "trainercallback": [4, 5], "optim": [4, 5], "lambdalr": [4, 5], "preprocess_logits_for_metr": [4, 5], "tensor": [4, 5], "return_output": [4, 5], "loss": [4, 5], "process": 4, "pytorch": 4, "whether": [4, 5], "adapt": [4, 6], "config_fil": 4, "train_arg": 4, "model_path": 4, "type_config": 4, "small": 4, "server_samantar_mixed_v": 4, "cpt_hour": 4, "batch_siz": 4, "32": 4, "max_length": 4, "1024": 4, "model_nam": [4, 6], "get": [4, 6], "checkpoint": [4, 6], "name": [4, 6], "from": [4, 5, 6], "an": 4, "organ": [4, 6], "id": [4, 6], "found": [4, 6], "otherwis": [4, 6], "data_path": [4, 6], "fraction": 4, "01": 4, "load": [4, 6], "specifi": 4, "path": [4, 6], "json_path": [4, 6], "json": [4, 6], "creat": 4, "provid": [4, 6], "contain": [4, 6], "print": [4, 6], "number": [4, 6], "trainabl": [4, 6], "inherit": 5, "transform": 5, "parent": 5, "detail": 6, "api": 6, "user": 6, "client_detail": 6, "access_level": 6, "contributor": 6, "verifi": 6, "org": 6, "els": 6, "given": 6, "split": 6, "valid": 6, "dictionari": 6, "datasetdict": 6, "local_path": 6, "low": 6, "rank": 6, "appli": 6, "target": 6, "local": 6, "save": 6, "autotoken": 6, "make": 6, "packag": [7, 8], "subpackag": [7, 8], "modul": [7, 8], "index": 7, "search": 7, "page": 7, "content": 8}, "objects": {"": [[0, 0, 0, "-", "fedem"]], "fedem": [[1, 0, 0, "-", "client"], [2, 0, 0, "-", "configurations"], [3, 0, 0, "-", "models"], [4, 0, 0, "-", "server"], [5, 0, 0, "-", "trainer"], [6, 0, 0, "-", "utils"]], "fedem.client": [[1, 1, 1, "", "Seshu"]], "fedem.client.Seshu": [[1, 2, 1, "", "push_to_hub"], [1, 2, 1, "", "tokenize"], [1, 2, 1, "", "train_lora"]], "fedem.configurations": [[2, 0, 0, "-", "mamba"]], "fedem.configurations.mamba": [[2, 1, 1, "", "MambaConfig"]], "fedem.configurations.mamba.MambaConfig": [[2, 3, 1, "", "model_type"]], "fedem.models": [[3, 0, 0, "-", "mamba"]], "fedem.models.mamba": [[3, 1, 1, "", "MambaBlock"], [3, 1, 1, "", "MambaForCausalLM"], [3, 1, 1, "", "MambaModel"], [3, 1, 1, "", "MambaPreTrainedModel"], [3, 1, 1, "", "MambaRMSNorm"]], "fedem.models.mamba.MambaBlock": [[3, 2, 1, "", "forward"], [3, 2, 1, "", "selective_scan"], [3, 2, 1, "", "ssm"]], "fedem.models.mamba.MambaForCausalLM": [[3, 2, 1, "", "forward"], [3, 2, 1, "", "get_decoder"], [3, 2, 1, "", "get_input_embeddings"], [3, 2, 1, "", "get_output_embeddings"], [3, 2, 1, "", "prepare_inputs_for_generation"], [3, 2, 1, "", "set_decoder"], [3, 2, 1, "", "set_input_embeddings"], [3, 2, 1, "", "set_output_embeddings"]], "fedem.models.mamba.MambaModel": [[3, 2, 1, "", "forward"], [3, 2, 1, "", "get_input_embeddings"], [3, 2, 1, "", "set_input_embeddings"]], "fedem.models.mamba.MambaPreTrainedModel": [[3, 3, 1, "", "base_model_prefix"], [3, 3, 1, "", "config_class"], [3, 3, 1, "", "supports_gradient_checkpointing"]], "fedem.models.mamba.MambaRMSNorm": [[3, 2, 1, "", "forward"]], "fedem.server": [[4, 1, 1, "", "MambaTrainer"], [4, 1, 1, "", "Seshu"], [4, 4, 1, "", "compute_loss"], [4, 4, 1, "", "create_JSON"], [4, 4, 1, "", "evaluation"], [4, 4, 1, "", "get_checkpoint_model"], [4, 4, 1, "", "get_data"], [4, 4, 1, "", "load_data"], [4, 4, 1, "", "load_json"], [4, 4, 1, "", "make_config"], [4, 4, 1, "", "model_merge"], [4, 4, 1, "", "print_trainable_parameters"]], "fedem.server.MambaTrainer": [[4, 2, 1, "", "compute_loss"]], "fedem.server.Seshu": [[4, 2, 1, "", "model_merge_eval"], [4, 2, 1, "", "pretrain"], [4, 2, 1, "", "tokenize"]], "fedem.trainer": [[5, 1, 1, "", "MambaTrainer"]], "fedem.trainer.MambaTrainer": [[5, 2, 1, "", "compute_loss"]], "fedem.utils": [[6, 4, 1, "", "get_checkpoint_model"], [6, 0, 0, "-", "huggingface"], [6, 4, 1, "", "load_data"], [6, 4, 1, "", "load_json"], [6, 4, 1, "", "load_model"], [6, 4, 1, "", "load_model_pretrained"], [6, 4, 1, "", "load_model_with_LoRA"], [6, 4, 1, "", "load_tokenizer"], [6, 4, 1, "", "make_config"], [6, 4, 1, "", "print_trainable_parameters"], [6, 4, 1, "", "split_data"]], "fedem.utils.huggingface": [[6, 4, 1, "", "get_client_details"], [6, 4, 1, "", "verify_user_with_org"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"]}, "titleterms": {"fedem": [0, 1, 2, 3, 4, 5, 6, 7, 8], "packag": [0, 1, 2, 3, 4, 5, 6], "subpackag": 0, "modul": [0, 1, 2, 3, 4, 5, 6], "content": [0, 1, 2, 3, 4, 5, 6, 7], "client": 1, "configur": 2, "submodul": [2, 3, 6], "mamba": [2, 3], "model": 3, "server": 4, "trainer": 5, "util": 6, "huggingfac": 6, "welcom": 7, "": 7, "document": 7, "indic": 7, "tabl": 7}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 60}, "alltitles": {"fedem package": [[0, "fedem-package"]], "Subpackages": [[0, "subpackages"]], "Module contents": [[0, "module-fedem"], [1, "module-fedem.client"], [2, "module-fedem.configurations"], [3, "module-fedem.models"], [4, "module-fedem.server"], [5, "module-fedem.trainer"], [6, "module-fedem.utils"]], "fedem.client package": [[1, "fedem-client-package"]], "fedem.configurations package": [[2, "fedem-configurations-package"]], "Submodules": [[2, "submodules"], [3, "submodules"], [6, "submodules"]], "fedem.configurations.mamba module": [[2, "module-fedem.configurations.mamba"]], "fedem.models package": [[3, "fedem-models-package"]], "fedem.models.mamba module": [[3, "module-fedem.models.mamba"]], "fedem.server package": [[4, "fedem-server-package"]], "fedem.trainer package": [[5, "fedem-trainer-package"]], "fedem.utils package": [[6, "fedem-utils-package"]], "fedem.utils.huggingface module": [[6, "module-fedem.utils.huggingface"]], "Welcome to fedem\u2019s documentation!": [[7, "welcome-to-fedem-s-documentation"]], "Contents:": [[7, null]], "Indices and tables": [[7, "indices-and-tables"]], "fedem": [[8, "fedem"]]}, "indexentries": {"fedem": [[0, "module-fedem"]], "module": [[0, "module-fedem"], [1, "module-fedem.client"], [2, "module-fedem.configurations"], [2, "module-fedem.configurations.mamba"], [3, "module-fedem.models"], [3, "module-fedem.models.mamba"], [4, "module-fedem.server"], [5, "module-fedem.trainer"], [6, "module-fedem.utils"], [6, "module-fedem.utils.huggingface"]], "seshu (class in fedem.client)": [[1, "fedem.client.Seshu"]], "fedem.client": [[1, "module-fedem.client"]], "push_to_hub() (fedem.client.seshu method)": [[1, "fedem.client.Seshu.push_to_hub"]], "tokenize() (fedem.client.seshu method)": [[1, "fedem.client.Seshu.tokenize"]], "train_lora() (fedem.client.seshu method)": [[1, "fedem.client.Seshu.train_lora"]], "mambaconfig (class in fedem.configurations.mamba)": [[2, "fedem.configurations.mamba.MambaConfig"]], "fedem.configurations": [[2, "module-fedem.configurations"]], "fedem.configurations.mamba": [[2, "module-fedem.configurations.mamba"]], "model_type (fedem.configurations.mamba.mambaconfig attribute)": [[2, "fedem.configurations.mamba.MambaConfig.model_type"]], "mambablock (class in fedem.models.mamba)": [[3, "fedem.models.mamba.MambaBlock"]], "mambaforcausallm (class in fedem.models.mamba)": [[3, "fedem.models.mamba.MambaForCausalLM"]], "mambamodel (class in fedem.models.mamba)": [[3, "fedem.models.mamba.MambaModel"]], "mambapretrainedmodel (class in fedem.models.mamba)": [[3, "fedem.models.mamba.MambaPreTrainedModel"]], "mambarmsnorm (class in fedem.models.mamba)": [[3, "fedem.models.mamba.MambaRMSNorm"]], "base_model_prefix (fedem.models.mamba.mambapretrainedmodel attribute)": [[3, "fedem.models.mamba.MambaPreTrainedModel.base_model_prefix"]], "config_class (fedem.models.mamba.mambapretrainedmodel attribute)": [[3, "fedem.models.mamba.MambaPreTrainedModel.config_class"]], "fedem.models": [[3, "module-fedem.models"]], "fedem.models.mamba": [[3, "module-fedem.models.mamba"]], "forward() (fedem.models.mamba.mambablock method)": [[3, "fedem.models.mamba.MambaBlock.forward"]], "forward() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.forward"]], "forward() (fedem.models.mamba.mambamodel method)": [[3, "fedem.models.mamba.MambaModel.forward"]], "forward() (fedem.models.mamba.mambarmsnorm method)": [[3, "fedem.models.mamba.MambaRMSNorm.forward"]], "get_decoder() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.get_decoder"]], "get_input_embeddings() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.get_input_embeddings"]], "get_input_embeddings() (fedem.models.mamba.mambamodel method)": [[3, "fedem.models.mamba.MambaModel.get_input_embeddings"]], "get_output_embeddings() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.get_output_embeddings"]], "prepare_inputs_for_generation() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.prepare_inputs_for_generation"]], "selective_scan() (fedem.models.mamba.mambablock method)": [[3, "fedem.models.mamba.MambaBlock.selective_scan"]], "set_decoder() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.set_decoder"]], "set_input_embeddings() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.set_input_embeddings"]], "set_input_embeddings() (fedem.models.mamba.mambamodel method)": [[3, "fedem.models.mamba.MambaModel.set_input_embeddings"]], "set_output_embeddings() (fedem.models.mamba.mambaforcausallm method)": [[3, "fedem.models.mamba.MambaForCausalLM.set_output_embeddings"]], "ssm() (fedem.models.mamba.mambablock method)": [[3, "fedem.models.mamba.MambaBlock.ssm"]], "supports_gradient_checkpointing (fedem.models.mamba.mambapretrainedmodel attribute)": [[3, "fedem.models.mamba.MambaPreTrainedModel.supports_gradient_checkpointing"]], "mambatrainer (class in fedem.server)": [[4, "fedem.server.MambaTrainer"]], "seshu (class in fedem.server)": [[4, "fedem.server.Seshu"]], "compute_loss() (fedem.server.mambatrainer method)": [[4, "fedem.server.MambaTrainer.compute_loss"]], "compute_loss() (in module fedem.server)": [[4, "fedem.server.compute_loss"]], "create_json() (in module fedem.server)": [[4, "fedem.server.create_JSON"]], "evaluation() (in module fedem.server)": [[4, "fedem.server.evaluation"]], "fedem.server": [[4, "module-fedem.server"]], "get_checkpoint_model() (in module fedem.server)": [[4, "fedem.server.get_checkpoint_model"]], "get_data() (in module fedem.server)": [[4, "fedem.server.get_data"]], "load_data() (in module fedem.server)": [[4, "fedem.server.load_data"]], "load_json() (in module fedem.server)": [[4, "fedem.server.load_json"]], "make_config() (in module fedem.server)": [[4, "fedem.server.make_config"]], "model_merge() (in module fedem.server)": [[4, "fedem.server.model_merge"]], "model_merge_eval() (fedem.server.seshu method)": [[4, "fedem.server.Seshu.model_merge_eval"]], "pretrain() (fedem.server.seshu method)": [[4, "fedem.server.Seshu.pretrain"]], "print_trainable_parameters() (in module fedem.server)": [[4, "fedem.server.print_trainable_parameters"]], "tokenize() (fedem.server.seshu method)": [[4, "fedem.server.Seshu.tokenize"]], "mambatrainer (class in fedem.trainer)": [[5, "fedem.trainer.MambaTrainer"]], "compute_loss() (fedem.trainer.mambatrainer method)": [[5, "fedem.trainer.MambaTrainer.compute_loss"]], "fedem.trainer": [[5, "module-fedem.trainer"]], "fedem.utils": [[6, "module-fedem.utils"]], "fedem.utils.huggingface": [[6, "module-fedem.utils.huggingface"]], "get_checkpoint_model() (in module fedem.utils)": [[6, "fedem.utils.get_checkpoint_model"]], "get_client_details() (in module fedem.utils.huggingface)": [[6, "fedem.utils.huggingface.get_client_details"]], "load_data() (in module fedem.utils)": [[6, "fedem.utils.load_data"]], "load_json() (in module fedem.utils)": [[6, "fedem.utils.load_json"]], "load_model() (in module fedem.utils)": [[6, "fedem.utils.load_model"]], "load_model_pretrained() (in module fedem.utils)": [[6, "fedem.utils.load_model_pretrained"]], "load_model_with_lora() (in module fedem.utils)": [[6, "fedem.utils.load_model_with_LoRA"]], "load_tokenizer() (in module fedem.utils)": [[6, "fedem.utils.load_tokenizer"]], "make_config() (in module fedem.utils)": [[6, "fedem.utils.make_config"]], "print_trainable_parameters() (in module fedem.utils)": [[6, "fedem.utils.print_trainable_parameters"]], "split_data() (in module fedem.utils)": [[6, "fedem.utils.split_data"]], "verify_user_with_org() (in module fedem.utils.huggingface)": [[6, "fedem.utils.huggingface.verify_user_with_org"]]}})